# Container Throughput Benchmark Worker
#
# Benchmarks container database throughput and calculates costs.
# Deploy with: wrangler deploy --config worker/bench-container-throughput.wrangler.toml
#
# @see https://developers.cloudflare.com/containers/

name = "bench-container-throughput-v2"
main = "bench-container-throughput.ts"
compatibility_date = "2026-01-01"
compatibility_flags = ["nodejs_compat"]

# Workers settings
account_id = "b6641681fe423910342b9ffa1364c76d"

# Performance settings for benchmark worker
[limits]
cpu_ms = 300000  # 5 minutes max CPU time for long benchmarks

# Observability
[observability]
enabled = true
head_sampling_rate = 1  # Full sampling during benchmarks

# =============================================================================
# Container Bindings
# =============================================================================
# Each container runs a database with an HTTP bridge for communication.
#
# Size tiers:
# - lite:           256MB RAM, 0.25 vCPU - $0.0025/hr
# - basic:          512MB RAM, 0.5 vCPU  - $0.005/hr
# - standard-1:     1GB RAM, 1 vCPU      - $0.01/hr
# - standard-2:     2GB RAM, 2 vCPU      - $0.02/hr
# - standard-4:     4GB RAM, 4 vCPU      - $0.04/hr
# - performance-8:  8GB RAM, 8 vCPU      - $0.08/hr
# - performance-16: 16GB RAM, 16 vCPU    - $0.16/hr
# =============================================================================

# PostgreSQL Container
[[containers]]
class_name = "PostgresBenchContainer"
image = "../containers/dockerfiles/Dockerfile.postgres"
instance_type = "standard-2"
max_instances = 2

# ClickHouse Container
[[containers]]
class_name = "ClickHouseBenchContainer"
image = "../containers/dockerfiles/Dockerfile.clickhouse"
instance_type = "standard-2"
max_instances = 2

# MongoDB Container
[[containers]]
class_name = "MongoBenchContainer"
image = "../containers/dockerfiles/Dockerfile.mongo"
instance_type = "standard-2"
max_instances = 2

# DuckDB Container
[[containers]]
class_name = "DuckDBBenchContainer"
image = "../containers/dockerfiles/Dockerfile.duckdb"
instance_type = "standard-1"
max_instances = 2

# SQLite Container
[[containers]]
class_name = "SQLiteBenchContainer"
image = "../containers/dockerfiles/Dockerfile.sqlite"
instance_type = "standard-1"
max_instances = 2

# =============================================================================
# Durable Object Bindings
# =============================================================================
# Durable Objects provide the interface for Worker-to-Container communication.
# =============================================================================

[[durable_objects.bindings]]
name = "POSTGRES_DO"
class_name = "PostgresBenchContainer"

[[durable_objects.bindings]]
name = "CLICKHOUSE_DO"
class_name = "ClickHouseBenchContainer"

[[durable_objects.bindings]]
name = "MONGO_DO"
class_name = "MongoBenchContainer"

[[durable_objects.bindings]]
name = "DUCKDB_DO"
class_name = "DuckDBBenchContainer"

[[durable_objects.bindings]]
name = "SQLITE_DO"
class_name = "SQLiteBenchContainer"

# =============================================================================
# Migrations
# =============================================================================
# Containers require new_sqlite_classes for SQLite storage used by the
# Container runtime for state management.
# =============================================================================

[[migrations]]
tag = "v1"
new_sqlite_classes = ["PostgresBenchContainer", "ClickHouseBenchContainer", "MongoBenchContainer", "DuckDBBenchContainer", "SQLiteBenchContainer"]

# =============================================================================
# R2 Bucket for Results
# =============================================================================

[[r2_buckets]]
binding = "RESULTS_BUCKET"
bucket_name = "bench-results"
# preview_bucket_name = "bench-results-preview"

# =============================================================================
# Environment Variables
# =============================================================================

[vars]
ENVIRONMENT = "production"
LOG_LEVEL = "info"

# Development environment
[env.dev]
vars = { ENVIRONMENT = "development", LOG_LEVEL = "debug" }

[env.dev.r2_buckets]
binding = "RESULTS_BUCKET"
bucket_name = "bench-results-dev"

# Staging environment
[env.staging]
vars = { ENVIRONMENT = "staging", LOG_LEVEL = "info" }

[env.staging.r2_buckets]
binding = "RESULTS_BUCKET"
bucket_name = "bench-results-staging"

# =============================================================================
# Deployment Notes
# =============================================================================

# To deploy this worker:
#
# 1. Create the R2 bucket:
#    wrangler r2 bucket create bench-results
#
# 2. Build and deploy:
#    wrangler deploy --config worker/bench-container-throughput.wrangler.toml
#
# 3. Run a benchmark:
#    curl -X POST "https://bench-container-throughput.your-subdomain.workers.dev/benchmark/container-throughput?database=postgres&concurrency=50&duration=60"
#
# 4. Run a quick test:
#    curl "https://bench-container-throughput.your-subdomain.workers.dev/benchmark/container-throughput/quick?database=postgres"
#
# Container size selection:
# - Use 'lite' or 'basic' for development/testing
# - Use 'standard-1' or 'standard-2' for production
# - Use 'performance-*' for high-throughput requirements
#
# Cost estimation at different scales:
#
# | Container Size  | Hourly Cost | 1M ops/mo | 100M ops/mo | 1B ops/mo |
# |-----------------|-------------|-----------|-------------|-----------|
# | lite            | $0.0025     | ~$1.80    | ~$180       | ~$1,800   |
# | basic           | $0.005      | ~$3.60    | ~$360       | ~$3,600   |
# | standard-1      | $0.01       | ~$7.20    | ~$720       | ~$7,200   |
# | standard-2      | $0.02       | ~$14.40   | ~$1,440     | ~$14,400  |
# | performance-8   | $0.08       | ~$57.60   | ~$5,760     | ~$57,600  |
#
# Compare with WASM + DO (2MB blob optimization):
# - Read: $0.001 per 1M rows (packed)
# - Write: $1.00 per 1M rows (packed)
# - At 100x packing: ~$0.01 per 1M ops
#
# Break-even analysis:
# - Low volume (<10K ops/hr): WASM + DO wins
# - Medium volume (10K-100K ops/hr): Depends on workload
# - High volume (>100K ops/hr): Container often wins
